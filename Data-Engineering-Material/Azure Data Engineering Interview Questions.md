### SQL Interview Questions

1. What is SQL?
2. What are the different types of SQL statements?
3. What is a Primary Key in SQL?
4. What is the difference between Primary Key and Unique Key?
5. What is a Foreign Key in SQL?
6. What is normalization in SQL, and why is it used?
7. What are the different normal forms in SQL?
8. What is denormalization?
9. What is an Index in SQL, and why do we use it?
10. What are the types of indexes in SQL?
11. What is a JOIN in SQL?
12. What are the different types of JOINs in SQL?
13. What is an INNER JOIN?
14. What is an OUTER JOIN?
15. What is a LEFT JOIN?
16. What is a RIGHT JOIN?
17. What is a CROSS JOIN?
18. What is a SELF JOIN?
19. What is the difference between UNION and UNION ALL?
20. What is the difference between WHERE and HAVING clauses?
21. What is a subquery in SQL?
22. What is a correlated subquery in SQL?
23. What is a VIEW in SQL?
24. What is the difference between a View and a Table?
25. What are the differences between DELETE, TRUNCATE, and DROP?
26. What is the difference between GROUP BY and ORDER BY in SQL?
27. What is a stored procedure in SQL?
28. What is a function in SQL?
29. What is a trigger in SQL?
30. What is a cursor in SQL?
31. What is a transaction in SQL?
32. What is ACID compliance in databases?
33. What is a clustered index in SQL?
34. What is a non-clustered index in SQL?
35. What is a composite key in SQL?
36. What is a default constraint in SQL?
37. What is a check constraint in SQL?
38. What is a NULL value in SQL?
39. How do you handle NULL values in SQL?
40. What is the COALESCE function in SQL?
41. What is the difference between CHAR and VARCHAR?
42. What is the difference between VARCHAR and NVARCHAR?
43. What is the purpose of the DISTINCT keyword in SQL?
44. What is the difference between COUNT(*), COUNT(column), and COUNT(DISTINCT column)?
45. What is the purpose of the LIMIT clause in SQL?
46. What is the RANK() function in SQL?
47. What is the difference between RANK() and DENSE_RANK()?
48. What is the ROW_NUMBER() function in SQL?
49. What is the difference between aggregate functions and scalar functions in SQL?
50. What is a materialized view in SQL?
51. What is the purpose of the EXISTS clause in SQL?
52. What is the difference between EXISTS and IN in SQL?
53. What are window functions in SQL?
54. What is the purpose of the OVER() clause in SQL?
55. What is the difference between IN and BETWEEN?
56. How can you retrieve duplicate records from a table?
57. How do you delete duplicate records in SQL?
58. What is the purpose of the CASE statement in SQL?
59. What is the MERGE statement in SQL?
60. What is the difference between a CROSS APPLY and OUTER APPLY?
61. What is a sequence in SQL?
62. What is the difference between a sequence and an identity column?
63. How can you implement paging in SQL?
64. How do you retrieve the first N records from a table?
65. What is the difference between ROLLUP and CUBE?
66. What is the PIVOT and UNPIVOT in SQL?
67. What is a recursive query in SQL?
68. How can you find the second highest salary in SQL?
69. How do you update data in SQL?
70. How do you perform a bulk insert in SQL?
71. How do you backup a database in SQL?
72. What is database replication in SQL?
73. What is partitioning in SQL?
74. What are database snapshots?
75. How do you handle error handling in SQL?
76. What is a temporary table in SQL?
77. What is the difference between a temporary table and a permanent table?
78. What are global and local temporary tables?
79. What are common table expressions (CTEs) in SQL?
80. What is the difference between a CTE and a subquery?
81. What is indexing and how does it affect query performance?
82. How do you measure query performance in SQL?
83. What is query optimization in SQL?
84. What is SQL injection and how can you prevent it?
85. What is a database schema in SQL?
86. What is a synonym in SQL?
87. What is collation in SQL?
88. What is the purpose of the SET keyword in SQL?
89. What is the difference between MINUS and EXCEPT in SQL?
90. What is a surrogate key in SQL?
91. What are windowing functions in SQL?
92. What is the purpose of the LEAD and LAG functions in SQL?
93. What is the NVL function in SQL?
94. What is the difference between DELETE and TRUNCATE?
95. What is the purpose of the TOP clause in SQL?
96. How do you perform string concatenation in SQL?
97. What is a database trigger?
98. How can you lock a table in SQL?
99. What is a deadlock in SQL?
100. How do you detect and resolve deadlocks in SQL?

### Database and Data Warehousing Interview Questions

1. What is a relational database?
2. What is the difference between a database and a data warehouse?
3. What is a star schema in data warehousing?
4. What is a snowflake schema?
5. What is a dimension table in a data warehouse?
6. What is a fact table in a data warehouse?
7. What is a slowly changing dimension (SCD)?
8. What is OLTP (Online Transaction Processing)?
9. What is OLAP (Online Analytical Processing)?
10. What are the different types of OLAP systems?
11. What is an ETL process in data warehousing?
12. What are the stages in the ETL process?
13. What is data mart?
14. What is the difference between a data mart and a data warehouse?
15. What is a surrogate key in data warehousing?
16. What is the purpose of the ETL tool in data warehousing?
17. What are the different types of data warehouse architectures?
18. What is a data lake?
19. What is data modeling in databases?
20. What are the different types of data models?
21. What is a schema in a database?
22. What is a database normalization?
23. What is a denormalization?
24. What are the benefits of database normalization?
25. What is data partitioning in databases?
26. What is indexing in databases and why is it important?
27. What is a materialized view in databases?
28. What is the role of a data architect in data warehousing?
29. What is a multidimensional database?
30. What is metadata in data warehousing?
31. What are the components of a data warehouse?
32. What is the difference between ER model and dimensional model?
33. What is a star schema and how does it work?
34. What is a factless fact table?
35. What are the types of fact tables?
36. What is data mining in data warehousing?
37. What is the difference between aggregation and granularity?
38. What is a conformed dimension in data warehousing?
39. What is a junk dimension in data warehousing?
40. What are data warehouse indexes?
41. What is data cleansing?
42. What is a hybrid data warehouse?
43. What is a logical data warehouse?
44. What is dimensional modeling in data warehousing?
45. What is a surrogate key and why is it used in data warehousing?
46. What are non-additive facts in data warehousing?
47. What is data staging in data warehousing?
48. What is a data pipeline?
49. What is a data cube in OLAP?
50. What is a composite key in a data warehouse?
51. What is a lookup table in data warehousing?
52. What are the benefits of a data warehouse?
53. What are the challenges of data warehousing?
54. What is business intelligence?
55. What is data governance in data warehousing?
56. What are data warehouse testing strategies?
57. What are data warehouse performance tuning techniques?
58. What is data profiling in data warehousing?
59. What is a surrogate key in a dimension table?
60. What is ETL testing?
61. What is the difference between incremental load and full load in ETL?
62. What is a data transformation in ETL?
63. What is a data integration?
64. What is data retention in a data warehouse?
65. What are factless fact tables?
66. What is the purpose of the fact table in a data warehouse?
67. What is a dependent data mart?
68. What is data consolidation in a data warehouse?
69. What are the key challenges in designing a data warehouse?
70. What is the Kimball methodology in data warehousing?
71. What is Inmon methodology in data warehousing?
72. What is a conformed fact?
73. What are degenerate dimensions?
74. What is an aggregate table in data warehousing?
75. What is ETL pipeline automation?
76. What are surrogate keys in data warehousing?
77. What is ELT (Extract, Load, Transform)?
78. What are the advantages of data warehouse automation tools?
79. What is active data warehousing?
80. What are OLAP cubes?
81. What is a hybrid OLAP (HOLAP)?
82. What is real-time data warehousing?
83. What is a data warehouse appliance?
84. What is the difference between data warehouse and data lake?
85. What is big data analytics in data warehousing?
86. What is columnar storage in data warehousing?
87. What is a snowflake schema?
88. What is the role of a data steward in a data warehouse?
89. What is a data integration platform?
90. What is predictive analytics in data warehousing?
91. What is a data warehouse bus architecture?
92. What is an operational data store (ODS)?
93. What is data lineage in data warehousing?
94. What are late-arriving facts in data warehousing?
95. What is an accumulative snapshot fact table?
96. What is data warehouse security?
97. What is the ETL pipeline in big data?
98. What is schema-on-read in data lakes?
99. What is the role of a data warehouse developer?
100. What are the best practices for building a data warehouse?



### Azure Databricks Interview Questions

1. What is Azure Databricks?
2. What are the key features of Azure Databricks?
3. How is Azure Databricks different from Apache Spark?
4. What is a workspace in Azure Databricks?
5. What is the purpose of Databricks clusters?
6. What are the different types of clusters in Azure Databricks?
7. How do you create a cluster in Azure Databricks?
8. What is auto-scaling in Azure Databricks?
9. What are the benefits of auto-scaling in Databricks?
10. What is a Databricks notebook?
11. What languages are supported in Databricks notebooks?
12. How do you create and run a notebook in Azure Databricks?
13. How does Azure Databricks integrate with Azure Data Lake Storage?
14. What are jobs in Azure Databricks?
15. How do you schedule a job in Azure Databricks?
16. What is the purpose of the Databricks Job Scheduler?
17. What is Databricks SQL?
18. How do you use SQL in Azure Databricks?
19. What are data frames in Databricks?
20. How do you create a data frame in Azure Databricks?
21. What are Delta Tables in Databricks?
22. What is Delta Lake in Azure Databricks?
23. What are the benefits of using Delta Lake?
24. How do you convert a Parquet table to a Delta table?
25. What is the purpose of ACID transactions in Delta Lake?
26. How does versioning work in Delta Lake?
27. What is a Databricks cluster policy?
28. What is the difference between a shared and an interactive cluster?
29. What is a job cluster in Azure Databricks?
30. How do you manage permissions in Azure Databricks?
31. What are the different roles in Azure Databricks?
32. How do you monitor cluster performance in Azure Databricks?
33. What is the Databricks REST API?
34. How do you use the Databricks CLI?
35. What is the purpose of a Databricks library?
36. What are the different types of libraries supported in Azure Databricks?
37. How do you install a library in a Databricks cluster?
38. What is Databricks MLflow?
39. How does MLflow help in managing machine learning workflows?
40. What is the difference between MLflow and Azure Machine Learning?
41. How do you track experiments in MLflow?
42. What are MLflow tracking APIs?
43. How do you deploy machine learning models in Azure Databricks?
44. How do you use Databricks with Azure Synapse Analytics?
45. How do you connect Databricks to a relational database?
46. What are the supported data sources in Azure Databricks?
47. How do you manage large datasets in Azure Databricks?
48. What is data partitioning in Databricks?
49. How do you optimize the performance of a Databricks cluster?
50. How do you handle data skew in Databricks?
51. What is Z-ordering in Delta Lake?
52. How do you handle schema evolution in Delta Lake?
53. What is schema enforcement in Delta Lake?
54. What are table properties in Databricks?
55. How do you create a global temporary view in Databricks?
56. What is the use of window functions in Databricks SQL?
57. How do you run a SQL query in Databricks using PySpark?
58. What is the significance of cache in Databricks?
59. How do you cache a DataFrame in Databricks?
60. What is a broadcast join in Databricks?
61. How do you implement a broadcast join in Databricks?
62. What is a lazy evaluation in Spark?
63. How does Spark handle large datasets in memory?
64. What is a shuffle operation in Spark?
65. How do you minimize shuffling in Databricks?
66. What is Spark SQL in Databricks?
67. How do you use windowing functions in Databricks?
68. How does Azure Databricks support streaming analytics?
69. What is Structured Streaming in Databricks?
70. How do you process streaming data in Databricks?
71. What is the difference between batch and stream processing in Databricks?
72. How do you ensure fault tolerance in streaming jobs in Databricks?
73. What is checkpointing in Spark Streaming?
74. How do you use Databricks with Apache Kafka?
75. How do you manage real-time data pipelines in Databricks?
76. What is Databricks Connect?
77. How do you connect Databricks to your IDE using Databricks Connect?
78. How do you export data from Databricks to external storage?
79. What is the difference between Delta Lake and Apache Hudi?
80. What are the key security features in Azure Databricks?
81. How do you implement Role-Based Access Control (RBAC) in Databricks?
82. How do you integrate Azure Key Vault with Databricks?
83. What is the purpose of secret scopes in Databricks?
84. How do you create and manage secrets in Azure Databricks?
85. What is Databricks Repos, and how do you use it?
86. How do you use Git with Databricks notebooks?
87. What are Databricks workflows?
88. How do you automate workflows in Azure Databricks?
89. What is the purpose of notebooks versioning in Databricks?
90. How do you run parallel jobs in Databricks?
91. How do you enable logging in Azure Databricks?
92. What is Databricks Runtime?
93. How do you upgrade the Databricks Runtime version in a cluster?
94. How do you use Databricks with Azure Event Hubs?
95. How does Databricks integrate with Azure DevOps?
96. How do you set up CI/CD for Databricks using Azure DevOps?
97. What are the best practices for managing Databricks notebooks?
98. How do you implement unit testing in Databricks?
99. How do you optimize cost in Databricks?
100. What are the common use cases of Azure Databricks?



### Azure Data Factory Interview Questions

1. What is Azure Data Factory?
2. What are the key components of Azure Data Factory?
3. What is the purpose of a pipeline in Azure Data Factory?
4. What are activities in Azure Data Factory?
5. What is a linked service in Azure Data Factory?
6. What are datasets in Azure Data Factory?
7. What are triggers in Azure Data Factory?
8. How do you create a pipeline in Azure Data Factory?
9. What is an Integration Runtime in Azure Data Factory?
10. What is the difference between Azure Integration Runtime and Self-hosted Integration Runtime?
11. How do you handle on-premises data sources in Azure Data Factory?
12. What is the Copy Activity in Azure Data Factory?
13. How do you use Data Flow in Azure Data Factory?
14. What is the difference between Data Flow and Control Flow in Azure Data Factory?
15. What is Mapping Data Flow in Azure Data Factory?
16. What is a Lookup Activity in Azure Data Factory?
17. How does the ForEach activity work in Azure Data Factory?
18. What is a Stored Procedure Activity in Azure Data Factory?
19. How do you schedule a pipeline in Azure Data Factory?
20. What are the different types of triggers available in Azure Data Factory?
21. What is an event-based trigger in Azure Data Factory?
22. How do you implement an incremental load in Azure Data Factory?
23. What is a tumbling window trigger in Azure Data Factory?
24. How do you monitor pipelines in Azure Data Factory?
25. What is the difference between an activity and a pipeline in Azure Data Factory?
26. How do you handle errors in Azure Data Factory?
27. How does the Retry policy work in Azure Data Factory?
28. What is the Get Metadata Activity in Azure Data Factory?
29. What is the role of a Data Factory parameter?
30. How do you use parameters in Azure Data Factory?
31. What are global parameters in Azure Data Factory?
32. How do you handle null values in Azure Data Factory?
33. How does Azure Data Factory handle schema drift?
34. What is schema mapping in Azure Data Factory?
35. How do you use variables in Azure Data Factory?
36. What is a dynamic content expression in Azure Data Factory?
37. How do you pass parameters between activities in Azure Data Factory?
38. What are custom activities in Azure Data Factory?
39. How do you use Azure Functions in Azure Data Factory?
40. How do you connect to Azure Data Lake using Azure Data Factory?
41. What is a REST API call in Azure Data Factory?
42. How do you use Web Activity in Azure Data Factory?
43. How do you handle JSON data in Azure Data Factory?
44. What is Data Flow Debug in Azure Data Factory?
45. What is the role of PolyBase in Azure Data Factory?
46. How do you load data from SQL Server to Azure SQL Database using Azure Data Factory?
47. How do you implement Change Data Capture (CDC) in Azure Data Factory?
48. How do you optimize pipeline performance in Azure Data Factory?
49. What are control activities in Azure Data Factory?
50. How do you implement loop activities in Azure Data Factory?
51. How do you implement conditional logic in Azure Data Factory?
52. What is the Wait Activity in Azure Data Factory?
53. How do you implement a parallel execution in Azure Data Factory?
54. How do you use the Execute Pipeline Activity in Azure Data Factory?
55. How do you validate data movement in Azure Data Factory?
56. What is an external activity in Azure Data Factory?
57. How do you handle versioning in Azure Data Factory?
58. How does Azure Data Factory integrate with Power BI?
59. What is the cost model for Azure Data Factory?
60. How do you secure pipelines in Azure Data Factory?
61. How do you use Azure Key Vault with Azure Data Factory?
62. How do you encrypt data in transit in Azure Data Factory?
63. What is the purpose of the Data Lake Analytics activity in Azure Data Factory?
64. How do you implement a data masking solution in Azure Data Factory?
65. What is the role of Azure Monitor in Azure Data Factory?
66. How do you manage pipeline dependencies in Azure Data Factory?
67. How do you use the Delete Activity in Azure Data Factory?
68. How do you handle large datasets in Azure Data Factory?
69. What is a pipeline concurrency limit in Azure Data Factory?
70. How do you manage pipeline execution order in Azure Data Factory?
71. How do you handle time zone settings in Azure Data Factory?
72. What is the significance of the pipeline run ID in Azure Data Factory?
73. How do you back up Azure Data Factory pipelines?
74. How do you use ARM templates in Azure Data Factory?
75. What is the purpose of CI/CD in Azure Data Factory?
76. How do you deploy Azure Data Factory pipelines across environments?
77. How do you implement logging in Azure Data Factory?
78. How do you configure alerts in Azure Data Factory?
79. How do you use the Debug feature in Azure Data Factory?
80. What is pipeline parameterization in Azure Data Factory?
81. How do you use the Flatten Transformation in Azure Data Factory?
82. How do you partition data in Azure Data Factory?
83. What is PolyBase and how is it used in Azure Data Factory?
84. How do you handle file formats such as CSV, JSON, and Parquet in Azure Data Factory?
85. How do you implement deduplication in Azure Data Factory?
86. How do you use branching in Azure Data Factory?
87. How do you configure retry policies for activities in Azure Data Factory?
88. What is the use of the Until Activity in Azure Data Factory?
89. How do you handle API pagination in Azure Data Factory?
90. How do you use Lookup and If Condition activities together in Azure Data Factory?
91. How do you create a delta load in Azure Data Factory?
92. How do you monitor Data Factory pipelines using Azure Log Analytics?
93. How do you manage different environments (dev, test, prod) in Azure Data Factory?
94. How do you set up disaster recovery for Azure Data Factory?
95. How do you implement Azure DevOps for Data Factory CI/CD?
96. What are the best practices for securing Azure Data Factory pipelines?
97. How do you create a data pipeline for real-time processing in Azure Data Factory?
98. How do you use Azure Data Factory with Azure Synapse Analytics?
99. What are the limitations of Azure Data Factory?
100. How do you handle cross-region data movement in Azure Data Factory?



### ADLS Gen2, Blob Storage, and Medallion Architecture Interview Questions

#### Azure Data Lake Storage Gen2 (ADLS Gen2) Questions

1. What is Azure Data Lake Storage Gen2 (ADLS Gen2)?
2. How does ADLS Gen2 differ from Azure Blob Storage?
3. What is hierarchical namespace in ADLS Gen2?
4. How does ADLS Gen2 support big data analytics?
5. What are the key features of ADLS Gen2?
6. How does ADLS Gen2 handle security and access control?
7. What is the role of ACLs (Access Control Lists) in ADLS Gen2?
8. How do you manage permissions in ADLS Gen2?
9. How do you set up role-based access control (RBAC) in ADLS Gen2?
10. What types of data can be stored in ADLS Gen2?
11. How is data organized in ADLS Gen2?
12. What is the difference between soft delete and hard delete in ADLS Gen2?
13. How do you manage snapshots in ADLS Gen2?
14. What is data lifecycle management in ADLS Gen2?
15. How do you manage versioning in ADLS Gen2?
16. What are the different pricing tiers available for ADLS Gen2?
17. How do you configure data redundancy in ADLS Gen2?
18. What is the purpose of data encryption in ADLS Gen2?
19. How do you use ADLS Gen2 with Azure Data Factory?
20. What are the performance optimization techniques for ADLS Gen2?
21. How does ADLS Gen2 integrate with Azure Databricks?
22. What is Azure Synapse Analytics and how does it work with ADLS Gen2?
23. How do you migrate data to ADLS Gen2 from on-premises systems?
24. How do you use Azure Blob API with ADLS Gen2?
25. How do you manage large datasets in ADLS Gen2?
26. How do you monitor and log activities in ADLS Gen2?
27. How do you configure diagnostic logging for ADLS Gen2?
28. What are the use cases for ADLS Gen2 in big data scenarios?
29. How do you implement data partitioning in ADLS Gen2?
30. How do you handle schema evolution in ADLS Gen2?
31. What is the role of Azure Active Directory in ADLS Gen2?
32. How do you configure access policies for ADLS Gen2?
33. How do you integrate ADLS Gen2 with Azure Stream Analytics?
34. What is the role of SAS tokens in ADLS Gen2?
35. How do you manage object replication in ADLS Gen2?
36. What are the differences between ADLS Gen2 and Amazon S3?
37. How does ADLS Gen2 support data governance?
38. What is a managed identity and how do you use it with ADLS Gen2?
39. How do you monitor storage costs in ADLS Gen2?
40. How do you create and manage file systems in ADLS Gen2?
41. What are the key security features of ADLS Gen2?
42. How do you enforce encryption at rest and in transit for ADLS Gen2?
43. How do you perform a data audit in ADLS Gen2?
44. How do you manage compliance requirements in ADLS Gen2?
45. How do you configure VNet service endpoints for ADLS Gen2?
46. What are the benefits of using ADLS Gen2 for machine learning workloads?
47. How do you optimize file access in ADLS Gen2?
48. How do you handle large-scale ingestion into ADLS Gen2?
49. What is the role of the Azure Data Lake Explorer tool?
50. How do you configure cross-region replication in ADLS Gen2?

#### Azure Blob Storage Questions

51. What is Azure Blob Storage?
52. How do you use Azure Blob Storage for unstructured data?
53. What are the different types of blobs supported by Azure Blob Storage?
54. What is the difference between block blobs, append blobs, and page blobs?
55. How do you create a Blob container in Azure Blob Storage?
56. What is the difference between Blob Storage and General Purpose Storage accounts?
57. How do you manage blob snapshots in Azure Blob Storage?
58. How do you set up blob lifecycle policies in Azure Blob Storage?
59. How do you configure blob versioning in Azure Blob Storage?
60. What is the role of SAS tokens in securing Azure Blob Storage?
61. How do you implement data redundancy in Blob Storage (LRS, ZRS, GRS)?
62. How does Azure Blob Storage handle large file uploads?
63. What is the Blob Storage Archive tier?
64. How do you move blobs between hot, cool, and archive tiers?
65. How do you access blob data using Azure Storage Explorer?
66. How do you manage data encryption in Azure Blob Storage?
67. How does Azure Blob Storage integrate with CDN (Content Delivery Network)?
68. What is the pricing structure for Azure Blob Storage?
69. How do you manage large-scale data ingestion in Blob Storage?
70. How do you secure blob data using private endpoints and VNet integration?
71. How do you monitor blob storage performance and usage?
72. How do you optimize cost management for Blob Storage?
73. What is the Blob Storage REST API, and how is it used?
74. How do you set up event-based triggers using Blob Storage?
75. How do you configure blob soft delete in Azure Blob Storage?
76. What are immutable blob storage policies and how are they used?
77. How do you automate data movement in Azure Blob Storage?
78. How do you create a Blob Storage static website?
79. How do you integrate Blob Storage with Azure Functions?
80. How do you perform data replication across regions in Blob Storage?
81. How do you use Blob Storage with Power BI for data analytics?
82. What are common use cases for Azure Blob Storage in data pipelines?
83. How do you implement logging and monitoring for Blob Storage?
84. What is the impact of hierarchical namespaces in Blob Storage?

#### Medallion Architecture Questions

85. What is the Medallion Architecture in a data lake?
86. How does the Medallion Architecture organize data layers?
87. What are the bronze, silver, and gold layers in the Medallion Architecture?
88. What type of data is stored in the bronze layer?
89. How do you process data in the silver layer of the Medallion Architecture?
90. How do you transform data into the gold layer in the Medallion Architecture?
91. How does the Medallion Architecture ensure data quality?
92. What are the benefits of using the Medallion Architecture in a data lake?
93. How do you manage data governance in the Medallion Architecture?
94. What is the role of Delta Lake in the Medallion Architecture?
95. How do you implement change data capture (CDC) in the Medallion Architecture?
96. How do you use the Medallion Architecture for real-time data processing?
97. What are the best practices for partitioning data in the Medallion Architecture?
98. How do you handle schema evolution in the Medallion Architecture?
99. How do you ensure data lineage in the Medallion Architecture?
100. What are common challenges when implementing the Medallion Architecture in Azure?


# 200 PySpark Interview Questions

### 1-20: PySpark Basics
1. What is PySpark?
2. How does PySpark differ from Apache Spark?
3. What is the architecture of PySpark?
4. Explain the role of Resilient Distributed Datasets (RDD) in PySpark.
5. How can you create an RDD in PySpark?
6. What are transformations in PySpark?
7. What are actions in PySpark?
8. Explain lazy evaluation in PySpark.
9. How do you persist an RDD in PySpark?
10. What is a DataFrame in PySpark?
11. How do DataFrames differ from RDDs?
12. How do you create a DataFrame in PySpark?
13. What is SparkSession in PySpark?
14. How do you read a CSV file in PySpark?
15. How do you write a DataFrame to a CSV file in PySpark?
16. How does the `select()` function work in PySpark?
17. How do you filter data in a PySpark DataFrame?
18. What is the `groupBy()` function in PySpark, and how do you use it?
19. How do you perform aggregations in PySpark?
20. Explain the role of UDFs (User Defined Functions) in PySpark.

### 21-40: PySpark SQL
21. What is PySpark SQL?
22. How do you run SQL queries in PySpark?
23. How do you create a temporary view in PySpark?
24. What is the difference between a temporary view and a global temporary view?
25. How do you register a DataFrame as a SQL table?
26. What are the different types of joins supported in PySpark?
27. How do you perform a join operation in PySpark?
28. How do you perform a left join in PySpark?
29. How do you perform an inner join in PySpark?
30. How do you perform a right join in PySpark?
31. What are window functions in PySpark SQL?
32. How do you use window functions for ranking in PySpark?
33. What is the purpose of the `orderBy()` function in PySpark?
34. How do you use the `withColumn()` function in PySpark?
35. How do you drop duplicates in a PySpark DataFrame?
36. How do you filter null values in PySpark?
37. How do you use the `cast()` function to change column data types in PySpark?
38. How do you use `alias()` in PySpark?
39. How do you handle missing values in PySpark?
40. What is the `distinct()` function in PySpark?

### 41-60: PySpark DataFrame Operations
41. How do you filter rows based on a condition in PySpark DataFrame?
42. How do you add a new column to a PySpark DataFrame?
43. How do you rename a column in PySpark DataFrame?
44. How do you drop a column in a PySpark DataFrame?
45. How do you group data in a PySpark DataFrame?
46. How do you pivot data in a PySpark DataFrame?
47. What is the `explode()` function in PySpark, and how do you use it?
48. How do you sort data in a PySpark DataFrame?
49. How do you handle duplicate rows in a PySpark DataFrame?
50. How do you sample data from a PySpark DataFrame?
51. How do you cache a DataFrame in PySpark?
52. What is the purpose of the `repartition()` function in PySpark?
53. How does `coalesce()` differ from `repartition()`?
54. How do you create an empty DataFrame in PySpark?
55. How do you perform a union of two DataFrames in PySpark?
56. What is the difference between `union()` and `unionByName()` in PySpark?
57. How do you append data to an existing DataFrame in PySpark?
58. How do you remove null values from a DataFrame in PySpark?
59. What is the purpose of `dropna()` in PySpark?
60. How do you count the number of rows in a PySpark DataFrame?

### 61-80: PySpark Performance Optimization
61. What are the best practices for optimizing PySpark jobs?
62. How do you use partitioning to optimize performance in PySpark?
63. What is the role of broadcast variables in PySpark?
64. How do you broadcast a variable in PySpark?
65. How do you use accumulators in PySpark, and what are their benefits?
66. How does PySpark handle memory management and garbage collection?
67. What is the difference between `persist()` and `cache()` in PySpark?
68. How do you use Kryo serialization in PySpark?
69. How does the `checkpoint()` function help in long-running PySpark jobs?
70. How can you tune the number of partitions in PySpark for performance improvement?
71. How do you perform skew data handling in PySpark?
72. What is dynamic partition pruning in PySpark?
73. How do you use Apache Arrow to speed up PySpark DataFrame operations?
74. What is Tungsten execution engine in PySpark?
75. How do you use Catalyst optimizer in PySpark for query optimization?
76. How do you optimize join operations in PySpark?
77. How do you handle small and large tables in PySpark join operations?
78. How do you set Spark configuration properties in PySpark?
79. How do you use Adaptive Query Execution (AQE) in PySpark?
80. What are the best practices for memory management in PySpark?

### 81-100: PySpark Advanced Operations
81. What are custom aggregators in PySpark?
82. How do you create a custom aggregator in PySpark?
83. What is the role of vectorized UDFs in PySpark?
84. How do you implement window functions in PySpark?
85. How do you calculate running totals using window functions in PySpark?
86. How do you perform lead and lag operations in PySpark?
87. How do you calculate rolling averages in PySpark?
88. How do you rank rows within a window partition in PySpark?
89. How do you perform cross join in PySpark?
90. How do you split a DataFrame into multiple DataFrames in PySpark?
91. What is the difference between `rdd.map()` and `df.withColumn()`?
92. How do you apply map-reduce operations in PySpark?
93. How do you serialize PySpark dataframes to Avro, Parquet, and ORC formats?
94. How do you read and write JSON data in PySpark?
95. How do you connect PySpark with Hive?
96. How do you work with external databases (JDBC) in PySpark?
97. What are columnar formats in PySpark, and why are they important?
98. How do you implement joins across multiple DataFrames in PySpark?
99. How do you handle categorical variables in PySpark?
100. How do you use Spark MLlib with PySpark?

### 101-120: PySpark Machine Learning (MLlib)
101. What is MLlib in PySpark?
102. How do you load data for machine learning in PySpark?
103. How do you perform feature engineering in PySpark?
104. How do you handle categorical features in PySpark MLlib?
105. What is the difference between StringIndexer and OneHotEncoder in PySpark?
106. How do you split data into training and test sets in PySpark?
107. How do you create a machine learning pipeline in PySpark?
108. How do you train a linear regression model in PySpark?
109. How do you train a logistic regression model in PySpark?
110. How do you evaluate a classification model in PySpark?
111. How do you use `MulticlassClassificationEvaluator` in PySpark?
112. How do you handle class imbalance in PySpark MLlib?
113. How do you perform cross-validation in PySpark?
114. What is the role of the `ParamGridBuilder` in PySpark?
115. How do you tune hyperparameters in PySpark?
116. How do you handle large datasets for machine learning in PySpark?
117. How do you perform clustering in PySpark?
118. How do you implement K-Means clustering in PySpark?
119. What is Decision Tree in PySpark MLlib?
120. How do you handle missing data in PySpark MLlib?

### 121-140: PySpark Streaming
121. What is PySpark Streaming?
122. How does PySpark Streaming handle real-time data?
123. What is the difference between DStream and DataFrame in PySpark Streaming?
124. How do you create a DStream in PySpark?
125. How do you use Kafka with PySpark Streaming?
126. How do you use a sliding window in PySpark Streaming?
127. How do you perform stateful transformations in PySpark Streaming?
128. What is Structured Streaming in PySpark?
129. How do you read a stream from a socket in PySpark?
130. How do you perform stream processing in PySpark?
131. What are the different output modes in PySpark Structured Streaming?
132. How do you checkpoint data in PySpark Streaming?
133. What is watermarking in PySpark Streaming?
134. How do you handle late data in PySpark Streaming?
135. How do you integrate PySpark Streaming with Apache Kafka?
136. What are the sources supported by PySpark Structured Streaming?
137. How do you handle failures in PySpark Streaming?
138. How do you use PySpark with Amazon Kinesis?
139. How does PySpark Streaming achieve fault tolerance?
140. What are the best practices for PySpark Streaming performance?

### 141-160: PySpark Data Sources and Formats
141. What data formats are supported by PySpark?
142. How do you read Parquet files in PySpark?
143. How do you write a DataFrame as a Parquet file in PySpark?
144. How do you read ORC files in PySpark?
145. How do you write a DataFrame as an ORC file in PySpark?
146. How do you read JSON files in PySpark?
147. How do you write a DataFrame as a JSON file in PySpark?
148. How do you read Avro files in PySpark?
149. How do you write a DataFrame as an Avro file in PySpark?
150. How do you handle nested data in PySpark?
151. How do you flatten a DataFrame with nested fields in PySpark?
152. How do you read data from an S3 bucket in PySpark?
153. How do you write data to an S3 bucket in PySpark?
154. How do you read data from HDFS in PySpark?
155. How do you write data to HDFS in PySpark?
156. How do you read data from a MySQL database in PySpark?
157. How do you write data to a MySQL database in PySpark?
158. How do you read from and write to PostgreSQL using PySpark?
159. How do you read data from Cassandra in PySpark?
160. How do you write data to Cassandra in PySpark?

### 161-180: PySpark Integration with Tools
161. How do you integrate PySpark with Hadoop?
162. How do you configure Hadoop Distributed File System (HDFS) in PySpark?
163. How do you use PySpark with Hive?
164. How do you integrate PySpark with AWS S3?
165. How do you use Google Cloud Storage with PySpark?
166. How do you integrate PySpark with Azure Blob Storage?
167. How do you connect PySpark with Google BigQuery?
168. How do you integrate PySpark with Azure Data Lake Storage (ADLS)?
169. How do you integrate PySpark with Apache HBase?
170. How do you use PySpark with Apache Cassandra?
171. How do you integrate PySpark with Elasticsearch?
172. How do you use PySpark with Apache Kafka?
173. How do you integrate PySpark with Apache Flink?
174. How do you integrate PySpark with TensorFlow?
175. How do you connect PySpark with SQL Server?
176. How do you use PySpark with Apache Airflow for orchestration?
177. How do you integrate PySpark with Apache NiFi?
178. How do you use PySpark with Docker containers?
179. How do you deploy PySpark applications on Kubernetes?
180. How do you monitor PySpark jobs with Ganglia and Prometheus?

### 181-200: PySpark Debugging and Troubleshooting
181. How do you debug PySpark applications?
182. What are common issues faced when working with PySpark?
183. How do you handle out-of-memory errors in PySpark?
184. How do you tune PySpark jobs for better performance?
185. How do you troubleshoot slow jobs in PySpark?
186. How do you handle schema mismatches in PySpark?
187. How do you handle corrupt data in PySpark?
188. How do you monitor PySpark jobs?
189. How do you use Spark UI for debugging PySpark jobs?
190. How do you handle failed stages in PySpark jobs?
191. How do you troubleshoot serialization issues in PySpark?
192. How do you resolve executor failures in PySpark?
193. What are common memory management issues in PySpark?
194. How do you use `explain()` for debugging query plans in PySpark?
195. How do you handle skewed data in PySpark?
196. How do you optimize shuffle operations in PySpark?
197. How do you handle checkpointing errors in PySpark?
198. How do you resolve performance bottlenecks in PySpark?
199. What tools do you use for profiling PySpark jobs?
200. How do you handle large datasets in PySpark?


# 100 Scenario-Based Azure Data Engineering Interview Questions

### 1-20: Azure Data Factory (ADF) Scenarios
1. How would you design an ADF pipeline to handle daily incremental data loads from an on-premises SQL Server database to Azure SQL Database?
2. You need to extract, transform, and load (ETL) data from multiple sources (Blob Storage, SQL, REST API) into a Data Warehouse. How would you implement this in ADF?
3. How would you implement error handling and retry logic in an ADF pipeline that interacts with an API?
4. You need to perform a data cleanup before ingestion using ADF. How would you approach this scenario?
5. How would you schedule an ADF pipeline to run based on a file trigger when a file is uploaded to Azure Blob Storage?
6. How do you implement a lookup activity in ADF to check for dependencies in a pipeline?
7. How would you copy data from an on-premises Oracle database to Azure Data Lake using ADF and Self-hosted Integration Runtime?
8. Explain how you would use ADFâ€™s mapping data flow to perform data transformation on incoming CSV files.
9. How would you configure an ADF pipeline to handle file-based data, considering files are uploaded in different formats (CSV, JSON, Parquet)?
10. What is your approach for managing and monitoring failed ADF pipeline executions in a production environment?
11. You need to copy only updated records from an Azure SQL Database to another database daily. How would you implement this in ADF?
12. How would you manage different environments (Dev, QA, Prod) using ADF?
13. How do you implement logging and monitoring for pipelines in ADF?
14. You have to move data from SFTP to Azure Blob Storage in real-time. How would you implement this using ADF?
15. How would you set up a complex pipeline that triggers multiple dependent pipelines in ADF?
16. How do you optimize ADF data flows for performance when transforming large datasets?
17. Explain how to use Azure Key Vault in ADF to manage secrets and connection strings securely.
18. You need to copy millions of records from SQL Server to Azure Data Lake. How would you ensure high performance and scalability in ADF?
19. Describe how you would handle schema drift when copying data from multiple sources into Azure Data Lake.
20. How would you implement version control for ADF pipelines in a CI/CD process?

### 21-40: Azure Data Lake Storage (ADLS) and Blob Storage Scenarios
21. How would you set up a folder structure in ADLS Gen2 for a data lake architecture following the Medallion (Bronze, Silver, Gold) approach?
22. How do you secure sensitive data in ADLS Gen2 using RBAC and ACL?
23. You have data stored in ADLS Gen2 that you need to query. How would you make this data accessible for querying without moving it to Azure SQL Data Warehouse?
24. How would you design a data retention policy for ADLS Gen2 to manage historical data efficiently?
25. How do you handle large file ingestion (e.g., 10 GB files) into ADLS Gen2 while optimizing read performance?
26. You need to move data from ADLS Gen2 to Azure Synapse Analytics. How would you do this while maintaining data integrity?
27. How would you migrate petabytes of data from on-premises to ADLS Gen2?
28. How would you implement partitioning in ADLS Gen2 to optimize query performance for large datasets?
29. Explain how to manage and store metadata for files ingested into ADLS Gen2.
30. You have millions of small files in ADLS Gen2. How would you handle this scenario to optimize performance and reduce costs?
31. How would you implement encryption at rest and in transit for data stored in Blob Storage or ADLS Gen2?
32. You need to integrate data stored in ADLS Gen2 with Power BI. How would you approach this?
33. Describe how you would use Data Lifecycle Management policies in ADLS Gen2 to optimize costs.
34. How would you set up a backup and disaster recovery solution for ADLS Gen2?
35. How would you implement data compression and decompression while writing large files to Blob Storage or ADLS Gen2?
36. How do you handle the ingestion of semi-structured data (e.g., JSON) into ADLS Gen2 and make it queryable?
37. How would you monitor the performance and health of your ADLS Gen2 environment?
38. You are dealing with IoT sensor data being stored in ADLS Gen2. How would you partition and organize this data for efficient analysis?
39. How do you configure role-based access and manage permissions in ADLS Gen2 for a multi-team setup?
40. Explain how you would ensure the data consistency and reliability in ADLS Gen2 when ingesting from multiple sources.

### 41-60: Azure Synapse Analytics Scenarios
41. How would you design an ETL pipeline in Azure Synapse Analytics that extracts data from multiple source systems, transforms it, and loads it into a data warehouse?
42. Explain how you would handle slowly changing dimensions (SCD) in Azure Synapse Analytics.
43. How do you implement partitioning in Synapse Analytics to optimize performance?
44. How would you design a data model in Azure Synapse Analytics for a retail company's sales data?
45. You need to integrate Synapse Analytics with Azure Machine Learning. How would you approach this?
46. Describe how you would manage the distribution of large tables across compute nodes in Synapse Analytics.
47. How would you perform a point-in-time restore of a database in Synapse Analytics?
48. How would you handle concurrent users querying the same large datasets in Synapse Analytics?
49. You need to perform a data migration from an on-premises SQL Data Warehouse to Azure Synapse Analytics. How would you plan this migration?
50. How do you implement row-level security (RLS) in Synapse Analytics?
51. How would you optimize a slow-running query in Synapse Analytics?
52. How would you design a data integration pipeline in Synapse Analytics for real-time data ingestion?
53. How do you manage different environments (Dev, Test, Prod) for Synapse Analytics?
54. How do you manage and monitor resource consumption in Azure Synapse Analytics?
55. How would you partition and manage data when dealing with large time-series datasets in Synapse Analytics?
56. How would you manage schema drift in Azure Synapse Analytics when ingesting data from diverse sources?
57. How do you integrate Synapse Analytics with ADLS Gen2?
58. How would you automate data loading and transformation using Azure Synapse Analytics pipelines?
59. How would you design a high-availability and disaster recovery strategy for Azure Synapse Analytics?
60. Explain how PolyBase can be used to query external data in Azure Synapse Analytics.

### 61-80: Azure Databricks Scenarios
61. How do you optimize Spark jobs running in Azure Databricks for performance when dealing with large datasets?
62. You are tasked with building a machine learning pipeline in Databricks using PySpark. How would you design it?
63. How do you implement incremental data processing in Azure Databricks?
64. Explain how you would integrate Azure Databricks with ADLS Gen2 for reading and writing data.
65. How would you handle skewed data in a PySpark job running on Databricks?
66. How do you manage and scale compute resources in Azure Databricks for different workloads?
67. You need to process real-time data in Databricks. How would you implement this?
68. How do you secure a Databricks cluster for sensitive data processing?
69. Explain how you would implement job scheduling in Azure Databricks.
70. How would you implement CDC (Change Data Capture) in Databricks using PySpark?
71. You need to process large amounts of streaming data in Databricks. How would you approach this?
72. How do you implement logging and monitoring in Databricks?
73. You have a dataset stored in ADLS Gen2, and you need to perform a complex transformation using PySpark in Databricks. How would you approach this?
74. Explain how Delta Lake can be used in Databricks to ensure ACID transactions.
75. How would you migrate existing Apache Spark jobs from an on-prem Hadoop environment to Azure Databricks?
76. You are tasked with handling sessionization of web logs in Databricks. How would you approach this problem?
77. Explain how you would perform a join between large datasets in Azure Databricks while avoiding shuffles.
78. How would you set up continuous integration and continuous deployment (CI/CD) for Databricks notebooks and jobs?
79. How do you handle schema evolution in Delta Lake tables in Databricks?
80. How would you monitor and troubleshoot Spark jobs in Azure Databricks?

### 81-100: Azure Data Engineering General Scenarios
81. You need to design a highly available data pipeline that processes both batch and streaming data. How would you implement this using Azure services?
82. How would you ensure data integrity and consistency when moving data across different Azure services?
83. You need to design a data pipeline that ingests IoT data and stores it for real-time analytics. How would you approach this using Azure?
84. How would you implement an end-to-end data governance solution using Azure Purview for a large organization?
85. Explain how you would handle schema validation during data ingestion from different source systems.
86. You need to design a data pipeline that processes unstructured data (e.g., logs) and provides insights. How would you do this in Azure?
87. How would you manage and monitor costs for a large-scale data engineering project on Azure?
88. You need to ensure compliance with data regulations such as GDPR. How would you implement data privacy and security measures in an Azure-based data pipeline?
89. How would you design a data lake architecture that supports both structured and unstructured data?
90. How would you implement fault tolerance and retry mechanisms in a cloud-based data pipeline using Azure services?
91. How do you design a scalable and high-performance data warehouse using Azure Synapse Analytics?
92. You need to process and analyze streaming data from multiple sources (e.g., Kafka, Event Hubs). How would you approach this using Azure Stream Analytics or Databricks?
93. How do you implement a disaster recovery strategy for a data pipeline running in Azure?
94. You need to perform real-time fraud detection using Azure services. What architecture would you propose?
95. How would you optimize the cost of running a large-scale data processing solution on Azure?
96. You need to ingest data from a variety of relational and NoSQL databases into Azure. How would you manage schema drift and evolving data structures?
97. How would you design a metadata-driven pipeline to automate ETL processes in Azure?
98. How would you implement encryption and secure data storage for sensitive customer data in Azure?
99. You need to integrate data from multiple systems and provide a unified view of customer data. How would you approach this using Azure Data Engineering tools?
100. How do you manage data quality and data lineage in Azure-based data solutions?

